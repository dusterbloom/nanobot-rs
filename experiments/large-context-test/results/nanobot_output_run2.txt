
[36m  â–¶ read_file({"path":"/home/peppi/Dev/nanobot/experiments/large-context-test/data/arxiv_paper)[0m[K[K[36m  â–¶ read_file[0m  [32mâœ“[0m [2m0ms[0m
    [2mâ”Œâ”€ output â”€[0m
    [2mâ”‚[0m id,title,authors,abstract,published,categories
    [2mâ”‚[0m 2602.13194v1,Semantic Chunking and the Entropy of Natural Language,Weishun Zhong; Doron Sivan; Tankut Can; Mikhail Katkov; Misha Tsodyks,"The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.",2026-02-13,cs.CL; cond-mat.dis-nn; cond-mat.stat-mech; cs.AI
    [2mâ”‚[0m 2602.13191v1,CoPE-VideoLM: Codec Primitives For Efficient Video Language Models,Sayan Deb Sarkar; RÃ©mi Pautrat; Ondrej Miksik; Marc Pollefeys; Iro Armeni; Mahdi Rad; Mihai Dusmanu,"Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their ...[truncated]
    [2mâ””â”€[0m
[36m  â–¶ read_file({"path":"/home/peppi/Dev/nanobot/experiments/large-context-test/data/arxiv_paper)[0m[K[6A[J[K[36m  â–¶ read_file[0m  [32mâœ“[0m [2m0ms[0m
    [2mâ”Œâ”€ output â”€[0m
    [2mâ”‚[0m id,title,authors,abstract,published,categories
    [2mâ”‚[0m 2602.13194v1,Semantic Chunking and the Entropy of Natural Language,Weishun Zhong; Doron Sivan; Tankut Can; Mikhail Katkov; Misha Tsodyks,"The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.",2026-02-13,cs.CL; cond-mat.dis-nn; cond-mat.stat-mech; cs.AI
    [2mâ”‚[0m 2602.13191v1,CoPE-VideoLM: Codec Primitives For Efficient Video Language Models,Sayan Deb Sarkar; RÃ©mi Pautrat; Ondrej Miksik; Marc Pollefeys; Iro Armeni; Mahdi Rad; Mihai Dusmanu,"Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their ...[truncated]
    [2mâ””â”€[0m
[K[2mÐ˜ 1w Â·Â·Â· ###[0m[K[2mÐ˜ 2w Â·Â·Â· ### Step[0m[K[2mÐ˜ 2w Â·Â·Â· ### Step [0m[K[2mÐ˜ 3w Â·Â·Â· ### Step 1[0m[K[2mÐ˜ 3w Â·Â·Â· ### Step 1:[0m[2m2026-02-16T18:33:34.582003Z[0m [33m WARN[0m [2mnanobot::providers::openai_compat[0m[2m:[0m LLM API returned status 500 Internal Server Error (base=http://localhost:8080/v1): {"error":{"code":500,"message":"Context size has been exceeded.","type":"server_error"}}
[2m2026-02-16T18:33:34.582038Z[0m [33m WARN[0m [2mnanobot::agent::compaction[0m[2m:[0m Compaction failed; disabling proactive compaction for this run: Summarization provider error: Error calling LLM (HTTP 500 Internal Server Error): {"error":{"code":500,"message":"Context size has been exceeded.","type":"server_error"}}
[K
